{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos criar nosso classificador Naive Bayes em Python. Inicialmente, podemos definir o Naive Bayes um modelo que se baseia no Teorema de Bayes e seu principal intuíto é classificar um objeto em uma determina classe de acordo com a probabilidade deste objeto pertencer a essa classe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcionamento do Naive Bayes:\n",
    "\n",
    "- Considere uma base de dados de treinamento contendo amostras classificadas em m classes distintas [c1, c2, c3,...cm]\n",
    "\n",
    "- Suponha que x é uma amostra a ser classificada (não está ma base de dados de treinamento). O classificador Naive Bayes, atribui x à classe c1 se a probabilidade condicional P[c1|x] é a mais alta, ou seja, P[c1|x] > P[cj|x], para todo cj, cj != ci\n",
    "\n",
    "    - P[ci|x] = probabilidade de um exemplo x peretencer à classe ci\n",
    "\n",
    "- Existem 3 tipos de modelos Naive Bayes chamados Gaussian, Multinomial e Bernoulli na biblioteca sklearn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos continuar utilizando o data set Breast Cancer Wisconsin Diagnostic para o estudo e dos modelos descristos acima, iremos utilizar o Gaussian. O primeiro passo é, portanto, importar a biblioteca sklearn e carregar o dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "dataset = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizando os dados da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = dataset['target_names']\n",
    "labels = dataset['target']\n",
    "feature_names = dataset['feature_names']\n",
    "features = dataset['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimindo os rótulos das classes (maligno e benigno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O comando abaixo mostra que a amostra está mapeada para os valores binários, onde 0 representa a classe maligna e 1 representa a classe benigna. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  1\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(\"\\n \",labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No código abaixo, iremos produzir os nomes dos atributos e os valores dos atributos. Podemos perceber que para cada instância de dados, temos um total de 30 atributos e seus nomes vão de mean radius, mean texture, mean perimeter, etc.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius\n",
      "mean texture\n",
      "mean perimeter\n",
      "mean area\n",
      "mean smoothness\n",
      "mean compactness\n",
      "mean concavity\n",
      "mean concave points\n",
      "mean symmetry\n",
      "mean fractal dimension\n",
      "radius error\n",
      "texture error\n",
      "perimeter error\n",
      "area error\n",
      "smoothness error\n",
      "compactness error\n",
      "concavity error\n",
      "concave points error\n",
      "symmetry error\n",
      "fractal dimension error\n",
      "worst radius\n",
      "worst texture\n",
      "worst perimeter\n",
      "worst area\n",
      "worst smoothness\n",
      "worst compactness\n",
      "worst concavity\n",
      "worst concave points\n",
      "worst symmetry\n",
      "worst fractal dimension\n",
      "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n"
     ]
    }
   ],
   "source": [
    "for i in range (30):\n",
    "    print(feature_names[i]) \n",
    "print (features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos dividir o dataset em um conjunto de treinamento e em um conjunto de teste. Isso pode ser feito a partir da função train_test_split que precisamos importar abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos dividir em 40% para conjunto de treinamento e o restante para conjunto teste com o comando abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, train_labels, test_labels = train_test_split(features, labels, test_size = 0.40, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos importar o modelo Gaussian do Naive Bayes e inicializar o modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos treinar o modelo ajustando os dados utilizando a função fit, onde ajusta o Gaussian Naive Bayes de acordo com uma matriz x,y, onde x são os vetores de treinamento (número de amostras e número de atributos) e y os valores correspondentes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gnb.fit(train, train_labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliar o modelo, realizando a predição nos dados de teste, ou seja, ele vai predizer valores (0 ou 1) para as classificações no conjunto de teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0\n",
      " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0\n",
      " 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1\n",
      " 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "preds = gnb.predict(test)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A série acima de 0's e 1's são os valores previstos para as classes tumorais, ou seja, malignos e benignos. Agora, vamos comparar as duas matrizes test_labels e preds para descobrir a precisão do nosso modelo utilizando a função accuracy_score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9517543859649122\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(test_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse caso, obtivemos 95,17% de precisão no nosso modelo. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
