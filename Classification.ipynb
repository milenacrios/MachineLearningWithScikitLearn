{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O processo de classificação é importante para que o algoritmo aprenda a partir dos dados de treinamento, onde estará indicado cada ponto de dado e sua devida classificação. Supondo que queremos desenvolver um algoritmo para classificar se uma imagem é um carro ou não, nesse caso teríamos um conjunto de imagens de treinamento com a classe é carro e com a classe não é carro. Em seguida, precisamos treinar o algoritmo utilizando as amostras de treinamento. É bastante utilizado em reconhecimento facil, identificação de Spam, entre outros. Para o primeiro passo, iremos importar a nossa biblioteca de sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de agora, iremos utilizar um banco de dados com a biblioteca. O banco de dados escolhido para esse estudo foi sobre diagnóstico de câncer de mama Wisconsin, em que é composto por vários tipos de tumores e duas classificações: \"maligno\" ou \"benigno\". Para importar o conjunto de dados descrito, basta importar o dataset com sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, precisamos carregar o dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dicionário é composto por uma lista de chaves,\n",
    "\n",
    "Nomes dos rótulos das classificações (target_name)\n",
    "Os rótulos reais (target)\n",
    "Nomes de atributo/recurso (feature_names)\n",
    "O atributo (feature)\n",
    "\n",
    "Para melhor organização, iremos criar novas variáveis para cada chave acima conforme o código abaixo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = dataset['target_names']\n",
    "labels = dataset['target']\n",
    "feature_names = dataset['feature_names']\n",
    "features = dataset['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos imprimir os rótulos de classe (maligno e benigno):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos exibir o rótulo de 20 instâncias de dados, onde é possível perceber que eles estão mapeados para os valores binários 0 e 1, onde 0 representa a classificação maligno e 1 benigno, contendo majoritariamente classificação maligno e apenas uma classificação para benigno.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  0\n",
      "\n",
      "  1\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(\"\\n \",labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No código abaixo, iremos produzir os nomes dos atributos e os valores dos atributos. Podemos perceber que para cada instância de dados, temos um total de 30 atributos e seus nomes vão de mean radius, mean texture, mean perimeter, etc.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius\n",
      "mean texture\n",
      "mean perimeter\n",
      "mean area\n",
      "mean smoothness\n",
      "mean compactness\n",
      "mean concavity\n",
      "mean concave points\n",
      "mean symmetry\n",
      "mean fractal dimension\n",
      "radius error\n",
      "texture error\n",
      "perimeter error\n",
      "area error\n",
      "smoothness error\n",
      "compactness error\n",
      "concavity error\n",
      "concave points error\n",
      "symmetry error\n",
      "fractal dimension error\n",
      "worst radius\n",
      "worst texture\n",
      "worst perimeter\n",
      "worst area\n",
      "worst smoothness\n",
      "worst compactness\n",
      "worst concavity\n",
      "worst concave points\n",
      "worst symmetry\n",
      "worst fractal dimension\n",
      "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n"
     ]
    }
   ],
   "source": [
    "for i in range (30):\n",
    "    print(feature_names[i])\n",
    "print (features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora iremos dividir o dataset em dois conjuntos, um para treinamento e outro para teste. Para realizar essa divisão, o sklearn fornece a função train_test_split() e para isso iremos importar ela no nosso código. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos dividir o dataset em 40% para teste e 60% para treinamento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, train_labels, test_labels = train_test_split(features, labels, test_size = 0.40, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para construir o modelo de classificação, vamos utilizar os conceitos do algoritmo Naive Bayes. Nesse caso precisamos fazer a sua importação através do comando abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora utilizamos o comando para inicializar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos ajustar os dados utilizando o comando fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gnb.fit(train, train_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos executar a classificação em uma matriz de vetores de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0\n",
      " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0\n",
      " 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1\n",
      " 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "preds = gnb.predict(test)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos realizar a comparação das duas matrizes, test_labels e preds para descobrir a precisão do modelo. Para isso vamos utilizar a função accuracy_score() para calcular a precisão, onde o conjunto de rótulos previstos para a amostra (preds) deve corresponder exatamente ao conjunto de rótulos correspondentes aos rótulos corretos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9517543859649122\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(test_labels, preds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado mostra que o classificados Naive Bayes teve 95,17% de precisão. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
